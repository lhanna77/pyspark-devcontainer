{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sql\n",
    "from lib import common_functions\n",
    "from lib import configuration\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c08d515090e4:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dp203</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa5a1d91b50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = common_functions.get_spark_session('dp203')\n",
    "spark.active()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('4e605fd1-4786-41c3-b1f7-86a45b497c3d')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_n_path = configuration.dp203_input_path+'/2019.csv'\n",
    "twenty_t_path = configuration.dp203_input_path+'/2020.csv'\n",
    "twenty_to_path = configuration.dp203_input_path+'/2021.csv'\n",
    "\n",
    "# Variable for unique folder name\n",
    "folderName = uuid.uuid4()\n",
    "\n",
    "folderName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------+-------------------+--------------------+--------------------+--------+---------+--------+\n",
      "|SalesOrderNumber|SalesOrderLineNumber| OrderDate|       CustomerName|               Email|                Item|Quantity|UnitPrice|     Tax|\n",
      "+----------------+--------------------+----------+-------------------+--------------------+--------------------+--------+---------+--------+\n",
      "|         SO49171|                   1|2021-01-01|      Mariah Foster|mariah21@adventur...|  Road-250 Black, 48|       1|2181.5625| 174.525|\n",
      "|         SO49172|                   1|2021-01-01|       Brian Howard|brian23@adventure...|    Road-250 Red, 44|       1|  2443.35| 195.468|\n",
      "|         SO49173|                   1|2021-01-01|      Linda Alvarez|linda19@adventure...|Mountain-200 Silv...|       1|2071.4197|165.7136|\n",
      "|         SO49174|                   1|2021-01-01|     Gina Hernandez|gina4@adventure-w...|Mountain-200 Silv...|       1|2071.4197|165.7136|\n",
      "|         SO49178|                   1|2021-01-01|          Beth Ruiz|beth4@adventure-w...|Road-550-W Yellow...|       1|1000.4375|  80.035|\n",
      "|         SO49179|                   1|2021-01-01|          Evan Ward|evan13@adventure-...|Road-550-W Yellow...|       1|1000.4375|  80.035|\n",
      "|         SO49175|                   1|2021-01-01|       Margaret Guo|margaret24@advent...|    Road-250 Red, 52|       1|  2443.35| 195.468|\n",
      "|         SO49180|                   1|2021-01-01|      Mitchell Yuan|mitchell6@adventu...|  Road-650 Black, 58|       1|   782.99| 62.6392|\n",
      "|         SO49176|                   1|2021-01-01|       Shawn Sharma|shawn11@adventure...|Mountain-200 Silv...|       1|2071.4197|165.7136|\n",
      "|         SO49177|                   1|2021-01-01|     Barbara Chande|barbara44@adventu...|Mountain-200 Silv...|       1|2071.4197|165.7136|\n",
      "|         SO49186|                   1|2021-01-02|            Cara Xu|cara8@adventure-w...|    Road-250 Red, 52|       1|  2443.35| 195.468|\n",
      "|         SO49187|                   1|2021-01-02|          Lacey Liu|lacey16@adventure...|  Road-250 Black, 58|       1|2181.5625| 174.525|\n",
      "|         SO49190|                   1|2021-01-02|           Omar Zhu|omar13@adventure-...|Road-550-W Yellow...|       1|1000.4375|  80.035|\n",
      "|         SO49185|                   1|2021-01-02|Cassandra Fernandez|cassandra17@adven...|Mountain-200 Blac...|       1|2049.0981|163.9279|\n",
      "|         SO49184|                   1|2021-01-02|    Monica Martinez|monica17@adventur...|Mountain-200 Blac...|       1|2049.0981|163.9279|\n",
      "|         SO49189|                   1|2021-01-02|     Marie Gonzalez|marie20@adventure...|  Road-650 Black, 48|       1|   782.99| 62.6392|\n",
      "|         SO49182|                   1|2021-01-02|     Alexandra Hall|alexandra89@adven...|    Road-250 Red, 48|       1|  2443.35| 195.468|\n",
      "|         SO49183|                   1|2021-01-02|     Alejandro Raji|alejandro46@adven...|    Road-250 Red, 52|       1|  2443.35| 195.468|\n",
      "|         SO49181|                   1|2021-01-02|    Derrick Jimï¿½nez|derrick5@adventur...|  Road-250 Black, 48|       1|2181.5625| 174.525|\n",
      "|         SO49188|                   1|2021-01-02|           Erin Cox|erin15@adventure-...|Mountain-200 Blac...|       1|2049.0981|163.9279|\n",
      "+----------------+--------------------+----------+-------------------+--------------------+--------------------+--------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32718"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "orderSchema = StructType([\n",
    "    StructField(\"SalesOrderNumber\", StringType()),\n",
    "    StructField(\"SalesOrderLineNumber\", IntegerType()),\n",
    "    StructField(\"OrderDate\", DateType()),\n",
    "    StructField(\"CustomerName\", StringType()),\n",
    "    StructField(\"Email\", StringType()),\n",
    "    StructField(\"Item\", StringType()),\n",
    "    StructField(\"Quantity\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", FloatType()),\n",
    "    StructField(\"Tax\", FloatType())\n",
    "    ])\n",
    "\n",
    "df = spark.read.option(\"header\", True).load(f'{configuration.dp203_input_path}/*.csv', format='csv', schema=orderSchema)\n",
    "df.count()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SalesOrderNumber: string (nullable = true)\n",
      " |-- SalesOrderLineNumber: integer (nullable = true)\n",
      " |-- OrderDate: date (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- UnitPrice: float (nullable = true)\n",
      " |-- Tax: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------+--------------------+--------------------+--------+---------+--------+---------+---------+\n",
      "|SalesOrderNumber|SalesOrderLineNumber| OrderDate|               Email|                Item|Quantity|UnitPrice|     Tax|FirstName| LastName|\n",
      "+----------------+--------------------+----------+--------------------+--------------------+--------+---------+--------+---------+---------+\n",
      "|         SO49171|                   1|2021-01-01|mariah21@adventur...|  Road-250 Black, 48|       1|2181.5625| 174.525|   Mariah|   Foster|\n",
      "|         SO49172|                   1|2021-01-01|brian23@adventure...|    Road-250 Red, 44|       1|  2443.35| 195.468|    Brian|   Howard|\n",
      "|         SO49173|                   1|2021-01-01|linda19@adventure...|Mountain-200 Silv...|       1|2071.4197|165.7136|    Linda|  Alvarez|\n",
      "|         SO49174|                   1|2021-01-01|gina4@adventure-w...|Mountain-200 Silv...|       1|2071.4197|165.7136|     Gina|Hernandez|\n",
      "|         SO49178|                   1|2021-01-01|beth4@adventure-w...|Road-550-W Yellow...|       1|1000.4375|  80.035|     Beth|     Ruiz|\n",
      "+----------------+--------------------+----------+--------------------+--------------------+--------+---------+--------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# Create the new FirstName and LastName fields\n",
    "transformed_df = df.withColumn(\"FirstName\", split(col(\"CustomerName\"), \" \").getItem(0)).withColumn(\"LastName\", split(col(\"CustomerName\"), \" \").getItem(1))\n",
    "\n",
    "# Remove the CustomerName field\n",
    "transformed_df = transformed_df.drop(\"CustomerName\")\n",
    "transformed_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data saved in 4e605fd1-4786-41c3-b1f7-86a45b497c3d!\n"
     ]
    }
   ],
   "source": [
    "transformed_df.write.mode(\"overwrite\").parquet(f'{configuration.dp203_output_path}/10/%s' % folderName)\n",
    "print (\"Transformed data saved in %s!\" % folderName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
